{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Networks Demystified [Part 1]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended [Jupyter Theme](https://github.com/dunovank/jupyter-themes) for presenting this notebook:\n",
    "````\n",
    "jt -t grade3 -cellw=90% -fs=20 -tfs=20 -ofs=20\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's we'll get a little deeper into the [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) series.\n",
    "- My hoped for outcome for you here is that you walk away with a fundamental understanding of the basic functioning of neural networks. There's lots of bells and whistles that we'll add later, but this module is just about **the basics**. \n",
    "- Really grasping the basics will serve you well when things start to get complex in the **deep learning** module.\n",
    "- To keep our focuse on the network itself, we'll use really really simple toy data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's get our data into numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = (hours sleeping, hours studying), y = Score on test\n",
    "X = np.array(([3,5], [5,1], [10,2]), dtype=float)\n",
    "y = np.array(([75], [82], [93]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  5.],\n",
       "       [ 5.,  1.],\n",
       "       [10.,  2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.],\n",
       "       [82.],\n",
       "       [93.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we doing again?\n",
    "Now, the big idea here, of course, is that we're going to use a neural network to predict your scores on a test based on how many hours you sleep and how many hours you study the night before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a **supervised regression** problem. \n",
    "- What is the difference between supervised and unsupervised machine learning?\n",
    "- What is the difference between regression and classification problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we get going, we need to scale our input data\n",
    "- It's crazy how easy it is to forget to do this, and how **big** of a difference it can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 1. ],\n",
       "       [0.5, 0.2],\n",
       "       [1. , 0.4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synapses\n",
    "- Synapses have a reall simple job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/nn_basics.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nuerons are responsible for adding up all their inputs and applying an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../graphics/NNQ8-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Setup out Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I recommend watching [Nueral Networks Demystified Parts 1 - 4](https://www.youtube.com/watch?v=UJwK6jAStmg) before this section. \n",
    "- We'll skip the details here, and fill back in if we have time. However the main focus of this lecture is backprop!\n",
    "- Here's our archicture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our key variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data, each row in an example| (numExamples, inputLayerSize)|\n",
    "|y |$$y$$|target data|(numExamples, outputLayerSize)|\n",
    "|W1 | $$W^{(1)}$$ | Layer 1 weights | (inputLayerSize, hiddenLayerSize) |\n",
    "|W2 | $$W^{(2)}$$ | Layer 2 weights | (hiddenLayerSize, outputLayerSize) |\n",
    "|z2 | $$z^{(2)}$$ | Layer 2 activation | (numExamples, hiddenLayerSize) |\n",
    "|a2 | $$a^{(2)}$$ | Layer 2 activity | (numExamples, hiddenLayerSize) |\n",
    "|z3 | $$z^{(3)}$$ | Layer 3 activation | (numExamples, outputLayerSize) |\n",
    "|J | $$J$$ | Cost | (1, outputLayerSize) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our \"forward\" equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And our python implementation of \"forward\" propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try out our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21106321],\n",
       "       [0.27291858],\n",
       "       [0.2758314 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x117cb59b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare estimate, yHat, to actually score\n",
    "fig = figure(0, (10, 6))\n",
    "bar([0,1,2], yHat.ravel(), width = 0.35, color='b', alpha=0.8)\n",
    "bar([0.35,1.35,2.35], y.ravel(), width = 0.35, color = 'g', alpha=0.8)\n",
    "\n",
    "grid(1)\n",
    "legend(['$\\hat{y}$', '$y$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are our predictions so bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## So, how do we make better predictions?\n",
    "- A good place to start is by measuing just how bad our performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/error_calculation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J = \\sum \\frac{1}{2}(y-\\hat{y})^2 \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- J is our cost! To train our network we must **minimize our cost function**.\n",
    "- What is the dimensionality of our cost?\n",
    "- Now that we've defined our cost mathematically, let's code it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21106321],\n",
       "       [0.27291858],\n",
       "       [0.2758314 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 0.5*sum((y-yHat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508843749874386"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Our whole job now is to find some values of $W^{(1)}$ and $W^{(2)}$ that minimize J!\n",
    "- How many numbers is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35700358,  0.98816579,  2.31303977],\n",
       "       [ 1.72524829, -0.29478134, -1.43392808]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.20844802],\n",
       "       [-0.66300639],\n",
       "       [-0.10351826]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just 9 numbers, how hard could this be!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/brute_force.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why can't we just try all the Ws?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a really important concept, we'll discuss in class quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Since we can't just \"try all the weights\", we're going to have to be *more clever*. \n",
    "- One interesting idea is to constrain our search be computing which direction is \"downhill\" in the 9 dimensional space of our cost function input. \n",
    "- This idea is called **Gradient Descent**, and it's cool AF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../graphics/nnd7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- This is kinda fun to think about in high dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/grad_descent.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When might this fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent fails if our loss function is non-convex\n",
    "- Somehow, this is much less of problem than reserachers originally thought. \n",
    "- Check out [Yann Lecun's Fun Talk](https://www.youtube.com/watch?v=8zdo6cnCW2w) on this for more info.\n",
    "- So ignoring that pesky convexity issue, if we're going to follow our gradient downwill, first we need to estimate or compute it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is our job for the rest of today. Given our equations thusfar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$\n",
    "$$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$\n",
    "$$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$\n",
    "$$\n",
    "J = \\sum \\frac{1}{2}(y-\\hat{y})^2 \\tag{5}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to estimate our gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = ? \n",
    "\\frac{\\partial J}{\\partial W^{(2)}} = ? \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try something a little different and workout the details using some guided notes. These will be on github, be sure to print before the lecture!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
